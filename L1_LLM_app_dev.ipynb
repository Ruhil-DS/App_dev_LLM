{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fbc1d1b8-0bbb-4c34-ba19-eedd7f0c1c8d",
   "metadata": {},
   "source": [
    "# LangChain: Models, Prompts and Output Parsers\n",
    "\n",
    "\n",
    "## Outline\n",
    "\n",
    " * Direct API calls to OpenAI\n",
    " * API calls through LangChain:\n",
    "   * Prompts\n",
    "   * Models\n",
    "   * Output parsers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "5e99baf7-b64e-4182-b8d1-a82fbfa7f2b0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# API Key setup\n",
    "import os\n",
    "\n",
    "api = !cat ../`ls -a ../ | grep \"gemini\"`\n",
    "\n",
    "api = api[0]\n",
    "\n",
    "os.environ['GOOGLE_API_KEY'] = api\n",
    "# universal variable, used by langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "77135bd9-851a-4d1c-8655-dac9dc1971ee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!pip install python-dotenv\n",
    "#!pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d332c985-23fc-4d0d-8006-48a0028659ac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# account for deprecation of LLM model\n",
    "import datetime\n",
    "# Get the current date\n",
    "current_date = datetime.datetime.now().date()\n",
    "\n",
    "# Define the date after which the model should be set to \"gpt-3.5-turbo\"\n",
    "target_date = datetime.date(2024, 6, 12)\n",
    "\n",
    "# Set the model variable based on the current date\n",
    "if current_date > target_date:\n",
    "    llm_model = \"gpt-3.5-turbo\"\n",
    "else:\n",
    "    llm_model = \"gpt-3.5-turbo-0301\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86abdebf-9acd-46a0-bd03-3e1e66506d67",
   "metadata": {},
   "source": [
    "# Chat API: Google AI + LangChain\n",
    "\n",
    "- We'll use LangChain to interact with Google's LLM\n",
    "\n",
    "- Original course was with ChatOpenAI but due to API restrictions, we'll use google's APIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "ec9a157c-17a6-4568-9c85-199d19d02dfe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!pip install --upgrade langchain\n",
    "#!pip install google-generativeai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "51ced97e-15d2-4385-8a38-f479a01ed9a9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI, ChatGooglePalm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0dbb583-9abc-404c-9e8b-b885d17b75cf",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "dd2995b2-9611-4d1c-afb8-154ec47a51f4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Temperature - parameter used to control the randomness of the response\n",
    "\n",
    "# chat = ChatOpenAI(temperature=0.0, model=llm_model)\n",
    "chat = ChatGooglePalm(temperature=0.0, model='Bison')\n",
    "\n",
    "# Created an AI wrapper around Google's model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab7b597f-cc09-4218-9b2b-547bb26c9eee",
   "metadata": {},
   "source": [
    "## Prompt Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "729c3a10-4dbe-4d66-b804-4f70733da742",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Translate the text that is delimited by triple backticks into a style that is {style}. text: ```{text}```Also, no need of boilerplate text. Just directly give me the answer\\n'"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "template_string = \"\"\"Translate the text \\\n",
    "that is delimited by triple backticks \\\n",
    "into a style that is {style}. \\\n",
    "\\\n",
    "text: ```{text}```\\\n",
    "Also, no need of boilerplate text. Just directly give me the answer\n",
    "\"\"\"\n",
    "\n",
    "template_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "37aa94bc-6562-483f-9054-c17d16288642",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt_template = ChatPromptTemplate.from_template(template_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "e4eb00d3-fc8d-4782-b97e-83b467ae9ccd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['style', 'text']"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_template.input_variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "c2078f62-1a19-460e-adf6-1de19daf60f7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Translate the text that is delimited by triple backticks into a style that is {style}. text: ```{text}```'"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_template.messages[0].prompt.template"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "031627c5-f188-4ac9-860c-863c9d09ab0d",
   "metadata": {},
   "source": [
    "- LangChain converted the string template to a more unified version that can be used across different LLMs\n",
    "- It automatically interpreted the variables that we had provided in the format: between {}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "b428d72a-ebae-4456-9b11-ebdd1fd2b2d3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "customer_style = '''American English \\\n",
    "in a calm and respectful tone\\\n",
    "'''\n",
    "\n",
    "customer_email = \"\"\"\n",
    "Arrr, I be fuming that me blender lid \\\n",
    "flew off and splattered me kitchen walls \\\n",
    "with smoothie! And to make matters worse, \\\n",
    "the warranty don't cover the cost of \\\n",
    "cleaning up me kitchen. I need yer help \\\n",
    "right now, matey!\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "30c2a6f4-a4f4-49b4-9f00-a06cba23c0b1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Let's pass in the values to the variable\n",
    "\n",
    "customer_msg = prompt_template.format_messages(\n",
    "    style = customer_style,\n",
    "    text = customer_email\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "12c2e197-d664-46bc-8798-67fd8a42feb4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Translate the text that is delimited by triple backticks into a style that is American English in a calm and respectful tone. text: ```\\nArrr, I be fuming that me blender lid flew off and splattered me kitchen walls with smoothie! And to make matters worse, the warranty don't cover the cost of cleaning up me kitchen. I need yer help right now, matey!\\n```\""
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "customer_msg[0].content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "57938a60-c5ef-4e92-afc4-2ad7c887c4e9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(customer_msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "ff8b73d6-a19a-4a27-829a-44c73d2b61d7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "langchain_core.messages.human.HumanMessage"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(customer_msg[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "222904fb-2783-4cc1-9643-f31dc971940e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "customer_resp = chat(customer_msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "220fb90f-23b3-405d-ae4f-bdd19b43a6c6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sure, I can help you with that. Here is the text translated into American English in a calm and respectful tone:\n",
      "\n",
      "\"I'm really angry that my blender lid flew off and splattered my kitchen walls with smoothie! And to make matters worse, the warranty doesn't cover the cost of cleaning up my kitchen. I need your help right now, please!\"\n",
      "\n",
      "I hope this is helpful!\n"
     ]
    }
   ],
   "source": [
    "print(customer_resp.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "f3ed61c9-c1d6-4ad3-b8b3-8a421e31ce91",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "service_reply = \"\"\"Hey there customer, \\\n",
    "the warranty does not cover \\\n",
    "cleaning expenses for your kitchen \\\n",
    "because it's your fault that \\\n",
    "you misused your blender \\\n",
    "by forgetting to put the lid on before \\\n",
    "starting the blender. \\\n",
    "Tough luck! See ya!\n",
    "\"\"\"\n",
    "\n",
    "service_style_pirate = \"\"\"\\\n",
    "a polite tone \\\n",
    "that speaks in English Pirate\\\n",
    "\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "555e57b2-d1eb-4c8d-9fad-b9112e3c5088",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "service_msg = prompt_template.format_messages(\n",
    "    style=service_style_pirate,\n",
    "    text=service_reply\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "d1753356-426e-4adf-8964-460c62a888b4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Translate the text that is delimited by triple backticks into a style that is a polite tone that speaks in English Pirate. text: ```Hey there customer, the warranty does not cover cleaning expenses for your kitchen because it's your fault that you misused your blender by forgetting to put the lid on before starting the blender. Tough luck! See ya!\\n```\""
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "service_msg[0].content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "b6b31d3b-b735-4d90-a1a3-8fa5464de08a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Ahoy there, matey! The warranty does not cover cleaning expenses for yer kitchen because it be yer fault that ye misused yer blender by forgettin' to put the lid on before startin' the blender. Tough luck! See ye later!\""
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "service_resp = chat(service_msg)\n",
    "service_resp.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da0c067d-4638-4014-8907-584c8ac5eb9c",
   "metadata": {},
   "source": [
    "## Output Parsers\n",
    "\n",
    "- We can also define how we would like the LLM output to look like. \n",
    "- The output can be formatted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "27dc661d-e869-4356-9034-981fc236a265",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'gift': False, 'delivery_days': 5, 'price_value': 'pretty affordable!'}"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This is how we expect out output to be:\n",
    "{\n",
    "  \"gift\": False,\n",
    "  \"delivery_days\": 5,\n",
    "  \"price_value\": \"pretty affordable!\"\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "85468a0f-2d21-406b-95bd-c271f85a9f07",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Review by the customer\n",
    "customer_review = \"\"\"\\\n",
    "This leaf blower is pretty amazing.  It has four settings:\\\n",
    "candle blower, gentle breeze, windy city, and tornado. \\\n",
    "It arrived in two days, just in time for my wife's \\\n",
    "anniversary present. \\\n",
    "I think my wife liked it so much she was speechless. \\\n",
    "So far I've been the only one using it, and I've been \\\n",
    "using it every other morning to clear the leaves on our lawn. \\\n",
    "It's slightly more expensive than the other leaf blowers \\\n",
    "out there, but I think it's worth it for the extra features.\n",
    "\"\"\"\n",
    "\n",
    "# Prompt template to tell LLM to get the details and \n",
    "# export in JSON\n",
    "review_template = \"\"\"\\\n",
    "For the following text, extract the following information:\n",
    "\n",
    "gift: Was the item purchased as a gift for someone else? \\\n",
    "Answer True if yes, False if not or unknown.\n",
    "\n",
    "delivery_days: How many days did it take for the product \\\n",
    "to arrive? If this information is not found, output -1.\n",
    "\n",
    "price_value: Extract any sentences about the value or price,\\\n",
    "and output them as a comma separated Python list.\n",
    "\n",
    "Format the output as JSON with the following keys:\n",
    "gift\n",
    "delivery_days\n",
    "price_value\n",
    "\n",
    "Note: I need a direct answer. \\\n",
    "No explation, no unneccesary text \\\n",
    "to explain the output. \\\n",
    "Just pure JSON output \\\n",
    " \\\n",
    "text: {text}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "bef8bf73-ebe3-402b-8c80-61b7cae4c635",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Converting prompt string to LangChain's prompt format\n",
    "prompt_template = ChatPromptTemplate.from_template(review_template)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "3e89f340-9ef7-4b02-99ee-f7b29b89c78f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['text'], messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['text'], template='For the following text, extract the following information:\\n\\ngift: Was the item purchased as a gift for someone else? Answer True if yes, False if not or unknown.\\n\\ndelivery_days: How many days did it take for the product to arrive? If this information is not found, output -1.\\n\\nprice_value: Extract any sentences about the value or price,and output them as a comma separated Python list.\\n\\nFormat the output as JSON with the following keys:\\ngift\\ndelivery_days\\nprice_value\\n\\nNote: I need a direct answer. No explation, no unneccesary text to explain the output. Just pure JSON output  text: {text}\\n'))])"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "ac0a7dcb-9c79-4435-969d-501267f713b3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```json\n",
      "{\n",
      "  \"gift\": true,\n",
      "  \"delivery_days\": 2,\n",
      "  \"price_value\": [\"just in time for my wife's anniversary present\"]\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "messages = prompt_template.format_messages(\n",
    "                            text = customer_review    \n",
    "                           )\n",
    "\n",
    "response = chat(messages)\n",
    "\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aacbcdb7-64da-4e88-a865-1f11dc2b6f8d",
   "metadata": {},
   "source": [
    "- It can be seen that the output is a string\n",
    "- The below code results in an error because we cannot use it as a json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "a2686518-e857-4845-9638-15be3b42784f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'get'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[195], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m response\u001b[38;5;241m.\u001b[39mcontent\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgift\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'get'"
     ]
    }
   ],
   "source": [
    "response.content.get('gift')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02de03a3-0e74-4d13-ad73-152027b18458",
   "metadata": {},
   "source": [
    "### Parse LLM output string into a python dictionary\n",
    "\n",
    "- To format the output, we need to create schemas\n",
    "- let's see that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "47b1c09e-b098-4953-9ec7-e9cc03031f75",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.output_parsers import ResponseSchema, StructuredOutputParser\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "33400ff0-3eb8-40f8-9d2c-8e40eeccfbf2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "gift_schema = ResponseSchema(name='gift',\n",
    "                            description=\"\"\"Was the item purchased as a gift for someone else? \\ \n",
    "                            Answer True if yes,\\\n",
    "                            False if not or Unknown.\"\"\")\n",
    "\n",
    "delivery_days_schema = ResponseSchema(name='delivery_days',\n",
    "                                      description=\"\"\"How many days \\\n",
    "                                      did it take for the product \\\n",
    "                                      to arrive? If this info \\\n",
    "                                      is not found, output -1.\"\"\")\n",
    "\n",
    "price_value_schema = ResponseSchema(name=\"price_value\",\n",
    "                                    description=\"\"\"Extract any\\\n",
    "                                    sentences about the value or \\\n",
    "                                    price, and output them as a \\\n",
    "                                    comma separated Python list.\"\"\")\n",
    "\n",
    "response_schema = [gift_schema, \n",
    "                   delivery_days_schema, \n",
    "                   price_value_schema]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "ecc6fa87-b105-4e7c-89e0-af59b7fa4d02",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResponseSchema(name='gift', description='Was the item purchased as a gift for someone else? \\\\ \\n                            Answer True if yes,                            False if not or Unknown.', type='string')"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gift_schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "623441e5-fd5e-4667-a401-541df2d9d770",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "output_parser = StructuredOutputParser.from_response_schemas(response_schema)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "c9fdbd6c-18bb-4596-b782-8cc571fc008f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "format_instructions = output_parser.get_format_instructions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "04625301-60df-4781-8fbd-89a76773ab0c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The output should be a markdown code snippet formatted in the following schema, including the leading and trailing \"```json\" and \"```\":\\n\\n```json\\n{\\n\\t\"gift\": string  // Was the item purchased as a gift for someone else? \\\\ \\n                            Answer True if yes,                            False if not or Unknown.\\n\\t\"delivery_days\": string  // How many days                                       did it take for the product                                       to arrive? If this info                                       is not found, output -1.\\n\\t\"price_value\": string  // Extract any                                    sentences about the value or                                     price, and output them as a                                     comma separated Python list.\\n}\\n```'"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# It defines the output format\n",
    "# Similar to how I defined it manually\n",
    "format_instructions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "bd6175e1-2650-491c-b72f-62bf4be4cc43",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "review_template_2 = \"\"\"\\\n",
    "For the following text, extract the following information:\n",
    "\n",
    "gift: Was the item purchased as a gift for someone else? \\\n",
    "Answer True if yes, False if not or unknown.\n",
    "\n",
    "delivery_days: How many days did it take for the product\\\n",
    "to arrive? If this information is not found, output -1.\n",
    "\n",
    "price_value: Extract any sentences about the value or price,\\\n",
    "and output them as a comma separated Python list.\n",
    "\n",
    "text: {text}\n",
    "\n",
    "{format_instructions}\n",
    "\"\"\"\n",
    "# We included the format instructions to the template\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "592a852d-610f-409b-82fa-a4e02cc3603c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_template(review_template_2)\n",
    "\n",
    "messages = prompt.format_messages(text=customer_review,\n",
    "                                  format_instructions=format_instructions\n",
    "                                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "63ea5776-7daa-4c0c-886f-a412889353b0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'For the following text, extract the following information:\\n\\ngift: Was the item purchased as a gift for someone else? Answer True if yes, False if not or unknown.\\n\\ndelivery_days: How many days did it take for the productto arrive? If this information is not found, output -1.\\n\\nprice_value: Extract any sentences about the value or price,and output them as a comma separated Python list.\\n\\ntext: This leaf blower is pretty amazing.  It has four settings:candle blower, gentle breeze, windy city, and tornado. It arrived in two days, just in time for my wife\\'s anniversary present. I think my wife liked it so much she was speechless. So far I\\'ve been the only one using it, and I\\'ve been using it every other morning to clear the leaves on our lawn. It\\'s slightly more expensive than the other leaf blowers out there, but I think it\\'s worth it for the extra features.\\n\\n\\nThe output should be a markdown code snippet formatted in the following schema, including the leading and trailing \"```json\" and \"```\":\\n\\n```json\\n{\\n\\t\"gift\": string  // Was the item purchased as a gift for someone else? \\\\ \\n                            Answer True if yes,                            False if not or Unknown.\\n\\t\"delivery_days\": string  // How many days                                       did it take for the product                                       to arrive? If this info                                       is not found, output -1.\\n\\t\"price_value\": string  // Extract any                                    sentences about the value or                                     price, and output them as a                                     comma separated Python list.\\n}\\n```\\n'"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages[0].content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "9e4b91f9-3c51-4c6f-967a-af5bfa6f628d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```json\n",
      "{\n",
      "  \"gift\": \"True\",\n",
      "  \"delivery_days\": \"2\",\n",
      "  \"price_value\": [\"slightly more expensive than the other leaf blowers out there\"]\n",
      "}\n",
      "```\n",
      "\n",
      "The following is the reasoning behind the output:\n",
      "\n",
      "* The item was purchased as a gift for someone else, as evidenced by the sentence \"It arrived in two days, just in time for my wife's anniversary present.\"\n",
      "* The product arrived in two days.\n",
      "* The price of the product is not explicitly stated, but it is mentioned that it is \"slightly more expensive than the other leaf blowers out there.\"\n"
     ]
    }
   ],
   "source": [
    "response = chat(messages)\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "5b79a3fa-d378-4250-b6e0-98b290745fb0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "output_dict = output_parser.parse(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "7c87fb6a-eaa8-4320-93e8-0e2cee69384e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'gift': 'True',\n",
       " 'delivery_days': '2',\n",
       " 'price_value': ['slightly more expensive than the other leaf blowers out there']}"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The output doesn't really care about any other text\n",
    "# Simply scrapes the relevant section of the response\n",
    "# and parses it into the required format\n",
    "output_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "3bda30d3-8481-4657-9fdd-379d1a26581d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(output_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "40b4b210-bcee-4f52-b679-8689b68a5bdd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2'"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_dict.get('delivery_days')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cbfcdd9-390b-4a95-a92d-af4cb0457638",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
